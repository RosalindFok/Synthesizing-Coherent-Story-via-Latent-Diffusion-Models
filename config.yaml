# device
mode: train  # train sample
gpu_ids: [ 0 ] # , 1, 2, 3 ]  # gpu ids
batch_size: 1  # batch size each item denotes one story
num_workers: 4  # number of workers
num_cpu_cores: -1  # number of cpu cores
seed: 0  # random seed
ckpt_dir: /lustre/S/yuxiaoyi/device/save_ckpt # checkpoint directory
run_name: your_run_name # name for this run

# task
dataset: oxford  # pororo flintstones vistsis vistdii
task: continuation  # continuation visualization

# train
init_lr: 1e-5  # initial learning rate
warmup_epochs: 1  # warmup epochs
max_epochs: 10 #50  # max epochs
train_model_file: null # model file for resume, none for train from scratch
freeze_clip: False  # whether to freeze clip
freeze_blip: False  # whether to freeze blip
freeze_resnet: False  # whether to freeze resnet

# sample
test_model_file: /lustre/S/yuxiaoyi/device/save_ckpt/last.ckpt # model file for test
calculate_fid: True  # whether to calculate FID scores
scheduler: ddim  # ddim pndm
guidance_scale: 6  # guidance scale
num_inference_steps: 10 # 250  # number of inference steps
sample_output_dir: /lustre/S/yuxiaoyi/sample/save_samples # output directory

oxford:
  hdf5_file: /lustre/S/yuxiaoyi/oxford_data/oxford.hdf5
  max_length: 91  # 改
  new_tokens: [ "fred", "barney", "wilma", "betty", "pebbles", "dino", "slate" ] # 改
  clip_embedding_tokens: 49412 # 改
  blip_embedding_tokens: 30525 # 改

hydra:
  run:
    dir: .
  output_subdir: null
hydra/job_logging: enabled
hydra/hydra_logging: enabled
